# @package _global_

defaults:
  - example_app
  - hparam_optimization_base
  - _self_

comment: ""

hparam_optimizer:
  sjob_id: "default"
  objectives_name: 'mock_obj'

# ....Overrides....................................
ms_model:
  hid_size: ${A_hid_size}
  num_layers: ${A_num_layers}

# ....sweep cfg key aliases........................
# Hack to shorten experiment directory name
A_hid_size: ???
A_num_layers: ???

# ====Multirun sweep===============================
hydra:
  mode: MULTIRUN
  sweeper:
    sampler:
      seed: 123
      # seed: range(123,1123,step=111)
    direction: minimize
    n_trials: 10
    n_jobs: 2 # Number of parallel workers
    params:
      A_hid_size: choice(444,666,999)
      A_num_layers: choice(1,2,3)


# Hydra multirun
# Ref
#   - https://hydra.cc/docs/1.3/tutorials/basic/running_your_app/multi-run/
#   - https://hydra.cc/docs/1.3/advanced/override_grammar/extended/#sweeps
#   - https://hydra.cc/docs/1.3/advanced/override_grammar/extended/#reordering-lists-and-sweeps
#
# Additional sweep types example
#   x=range(5)                                # 0-4
#   x=range(1,5)                              # 1-4
#   x=range(0,10,step=3.3)                    # 0.0, 3.3, 6.6, 9.9
#
#   x=choice(0.0,9.1,10.2)                    # 0.0, 9.1, 10.2
#   x=interval(1,5)                           # 1.0 <= x < 5.0, auto-cast to floats
#   x=tag(foo,bar,interval(0,1))              # 1.0 <= x < 1.0, tags=[foo,bar]
#   x=extend_list(11,12)                      # x=[1,2,3] -> x=[1,2,3,11,12]
#
#   shuffle(a,b,c)                            # shuffled a,b,c
#   shuffle(choice(a,b,c))                    # shuffled choice(a,b,c)
#   shuffle(range(1,10))                      # shuffled range(1,10)
#
#   schema=glob(*)                            # warehouse,support,school
#   schema=glob(*,exclude=w*)                 # support,school
#   schema=glob([s*,w*],exclude=school)       # support,warehouse
#   Note: A glob selects from all options in the config group.
